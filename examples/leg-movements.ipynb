{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "# os.chdir(Path(os.path.abspath(\"\")).parent)\n",
    "os.chdir('/home/alexnz/Projects/detr')  # Change this path!\n",
    "from mros_data.datamodule import SleepEventDataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datamodule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SleepEventDataModule` class contains logic to iterate over event data by wrapping a `SleepEventDataset` class.\n",
    "The datamodule is also responsible for splitting the data into train/eval partitions using the `setup()` method, and the user can then get a PyTorch `DataLoader` for each partition from the respective `*_dataloader()` methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass a dictionary of parameters to the datamodule class in order to instantiate it.\n",
    "The only event-specific parameters of note are `events`, `default_event_window_duration`, `fs`, and `picks`, corresponding to the event code/event name, duration of default events, sampling frequency, and the specific channels to include.\n",
    "\n",
    "Any transformations of the input data, such as short-time Fourier or continuous wavelet transforms can be included by the `transform` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mros_data.datamodule.transforms import STFTTransform\n",
    "\n",
    "params = dict(\n",
    "    data_dir=\"data/processed/mros/lm\",\n",
    "    batch_size=16,\n",
    "    n_eval=2,\n",
    "    n_test=2,\n",
    "    num_workers=0,\n",
    "    seed=1337,\n",
    "    events={\"lm\": \"Leg movement\"},\n",
    "    window_duration=600,  # seconds\n",
    "    cache_data=True,\n",
    "    default_event_window_duration=[15],\n",
    "    event_buffer_duration=3,\n",
    "    factor_overlap=2,\n",
    "    fs=64,\n",
    "    matching_overlap=0.5,\n",
    "    n_jobs=-1,\n",
    "    n_records=10,\n",
    "    picks=[\"legl\", \"legr\"],\n",
    "    # transform=MultitaperTransform(128, 0.5, 35.0, tw=8.0, normalize=True),\n",
    "    transform=STFTTransform(\n",
    "        fs=64, segment_size=int(4.0 * 64), step_size=int(0.125 * 64), nfft=1024, normalize=True\n",
    "    ),\n",
    "    scaling=\"robust\",\n",
    ")\n",
    "dm = SleepEventDataModule(**params)\n",
    "print(dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset into train/eval partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The datamodule will split the dataset into train/eval partitions by calling the setup() method.\n",
    "dm.setup('fit')\n",
    "train_dl, eval_dl = dm.train_dataloader(), dm.val_dataloader()\n",
    "\n",
    "# The dataloaders are generators, ie. we can iterate over them using a for-loop.\n",
    "for i, (data, events, records, *_) in enumerate(train_dl):\n",
    "    if i < 1:\n",
    "        print(f'Batch size: {data.shape[0]} | No. channels: {data.shape[1]} | No. timepoints {data.shape[-1]} | No. events: {sum([ev.shape[0] for ev in events])} | Data sample size: {list(data.shape[1:])} ')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above line tells us that the batch contains 16 windows of shape (2, 513, 4801) with 2 channels and 4801 time points.\n",
    "The last number tells us that there are 513 frequency bins in the STFT (the `nfft` parameter is set to 1024, but since we have real data, the spectra will be symmetric, ie. the positive and negative frequency components are the same)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access the underlying datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The underlying data windows can be accessed by indexing into the dataset. This will call the __getitem__() method and yield the signals, and associated events. \n",
    "The events' start times and durations are normalized to the window, ie. an event with elements (0.1, 0.025) in a 10 min window will start at 10 min x 60 s / min x 0.1 = 60 s , and will last 10 min x 60 s / min x 0.025 = 15 s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dm.train\n",
    "sample = train_ds[1]\n",
    "record = sample['record']\n",
    "data = sample['signal']\n",
    "events = sample['events']\n",
    "print(sample.keys())\n",
    "print(f'Record: {record} | No. channels: {data.shape[0]} | No. timepoints: {data.shape[-1]} | No. events: {len(events)} | Data shape: {data.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to described above, the print statement tells us that this sample contains 2 channels and 4801 timepoints.\n",
    "The remaining number describes the number of frequency components in the STFT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot signals in the underlying dataset by using the `plot_signals()` method in the `SleepEventDataset`. Simply provide an index in the range `[0, len(dataset)]` and optionally a list of the applied channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.plot_signals(0, channel_names=['Leg L', \"Leg R\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming data on the fly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the `transform` argument in the `SleepEventDataModule`, we can get spectrograms of the data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.plot_spect(0, channel_idx=0, window_size=int(4.0 * train_ds.fs), step_size=int(0.125 * train_ds.fs), nfft=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also combine the plots by using the `plot()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "train_ds.plot(0, channel_names=['Leg L', 'Leg R'], channel_idx=0, window_size=int(4.0 * train_ds.fs), step_size=int(0.125 * train_ds.fs), nfft=1024)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87f2bffab538fc57cb12ba16c255d8f2693dd38c7d4613c8bde43278bc7344c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
